<!DOCTYPE html>
<html>
<head>
<title>Page Title</title>
</head>
<body background='bg.jpeg'>

<center><h1>Quick lookups</h1></center> 

<table style="width:100%">
	<tr>
		<td><h2><center>Data Pre Processing , Machine learning </center></h2>
		</td>	
	</tr>
	<tr>
		<td><h3>Importing the dataset</h3></td>
		<td><h3>Splitting  the dataset into training and test dataset</h3></td>
	</tr>
	<tr>
		<td>
			dataset = pd.read_csv('Data.csv')<br>
			X = dataset.iloc[:, :-1].values<br>
			y = dataset.iloc[:, 3].values<br>
		</td>
		<td>
			from sklearn.model_selection import train_test_split<br>
			X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1/3, random_state=0)<br>
			
		</td>
	</tr>
	<tr>
		<td><h3>Encoding categorical data</h3></td>
		<td><h3>Polynomial fit</h3></td>
	</tr>
    <tr>
		<td>
			# Encoding the Independent Variable<br>
			from sklearn.compose import ColumnTransformer<br>
			from sklearn.preprocessing import LabelEncoder, OneHotEncoder<br>

			ct = ColumnTransformer([('encoder', OneHotEncoder(), [3])], remainder='passthrough')<br>
			X = np.array(ct.fit_transform(X), dtype=np.float)<br>
		</td>
		<td>
			#first we transform into polynomial fit AND THEN  we fit that in linear model<br>
			from sklearn.preprocessing import PolynomialFeatures<br>
			polyreg = PolynomialFeatures(degree = 4)# at first i took 2,3 degree but 4 is giving better result<br>
			X_poly = polyreg.fit_transform(X)<br>
			#now fit<br>
			lin_reg = LinearRegression()<br>
			lin_reg.fit(X_poly, y)<br>

		</td>
	</tr>
	<tr>
		<td><h3>Visualization of linear regression</h3></td>
		<td><h3>Feature Scaling</h3></td>
	</tr>
	<tr>
		<td>
			plt.scatter(X,y,color ='red')<br>
			plt.plot(X,lin_reg.predict(polyreg.fit_transform(X)),color='blue')<br>
			#using polyreg.fit and not X_poly because we can later just subsitute x and into x_grid ands not forget totransform<br>
			plt.title('Truth or bluf poly')<br>
		</td>
		<td>
			from sklearn.preprocessing import StandardScaler<br>
			sc = StandardScaler()<br>
			X_train = sc.fit_transform(X_train)<br>
			X_test = sc.transform(X_test)<br>
		</td>
	</tr>
	<tr>
		<td><h3>Logistic Regression</h3></td>
		<td><h3>Visualization of confusion matrix</h3></td>
	</tr>
	<tr>
		<td>from sklearn.linear_model import LogisticRegression</br>
			classifier = LogisticRegression(random_state=0)</br>
			classifier.fit(X_train,y_train)</br>
		</td>
		<td>from matplotlib.colors import ListedColormap</br>
			X_set, y_set = X_train, y_train</br>
			X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),</br>
								 np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))</br>
			plt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),</br>
						 alpha = 0.75, cmap = ListedColormap(('red', 'green')))</br>
			plt.xlim(X1.min(), X1.max())</br>
			plt.ylim(X2.min(), X2.max())</br>
			for i, j in enumerate(np.unique(y_set)):</br>
				plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],</br>
							c = ListedColormap(('red', 'green'))(i), label = j)</br>
			plt.title('Logistic Regression (Training set)')</br>
			plt.xlabel('Age')</br>
			plt.ylabel('Estimated Salary')</br>
			plt.legend()</br>
			plt.show()</br>
		</td>
	</tr>
		<tr>
		<td><h3>head1</h3></td>
		<td><h3>head2</h3></td>
	</tr>
	<tr>
</table>


</body>
</html>